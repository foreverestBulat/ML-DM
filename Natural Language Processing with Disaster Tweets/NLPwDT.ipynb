{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "# Description\n",
    "Добро пожаловать на один из наших конкурсов \"Начало работы\"!\n",
    "Этот конкурс идеально подходит для специалистов по обработке данных, которые хотят начать работать с обработкой естественного языка. Набор данных конкурентов не слишком велик, и даже если у вас не так много персональных вычислительных мощностей, вы можете выполнять всю работу в нашей бесплатной среде Jupyter Notebooks под названием Kaggle Notebooks, которая не требует настройки.\n",
    "\n",
    "# Dataset Description\n",
    "Какие файлы мне нужны?\n",
    "Вам понадобятся train.csv, test.csv и sample_submission.csv.\n",
    "\n",
    "Какой формат данных мне следует ожидать?\n",
    "Каждый образец в train и тестовом наборе содержит следующую информацию:\n",
    "\n",
    "Текст твита\n",
    "Ключевое слово из этого твита (хотя оно может быть пустым!)\n",
    "Место, откуда был отправлен твит (также может быть пустым)\n",
    "Что я предсказываю?\n",
    "Вы предсказываете, будет ли данный твит посвящен реальной катастрофе или нет. Если да, то прогнозируем значение 1. Если нет, то прогнозируем значение 0.\n",
    "\n",
    "Файлы\n",
    "- `train.csv` - обучающий набор\n",
    "- `test.csv` - тестовый набор\n",
    "- `sample_submission.csv` - файл с образцом отправки в правильном формате\n",
    "\n",
    "Столбцы\n",
    "- `id` - уникальный идентификатор для каждого\n",
    "- `text` - текст твита\n",
    "- `location` - местоположение, из которого был отправлен твит (может быть пустым)\n",
    "- `keyword` - конкретное ключевое слово из твита (может быть пустым)\n",
    "- `target` - только в train.csv это означает, относится ли твит к реальной катастрофе (1) или нет (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = 'nlp-getting-started/train.csv'\n",
    "test_path = 'nlp-getting-started/test.csv'\n",
    "ss_path = 'nlp-getting-started/sample_submission.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "ss_data = pd.read_csv(ss_path)\n",
    "\n",
    "target_variable = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.info())\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4866570\ttotal: 171ms\tremaining: 4m 15s\n",
      "100:\tlearn: 0.4043031\ttotal: 11.9s\tremaining: 2m 44s\n",
      "200:\tlearn: 0.3833331\ttotal: 22.8s\tremaining: 2m 27s\n",
      "300:\tlearn: 0.3692750\ttotal: 34.9s\tremaining: 2m 19s\n",
      "400:\tlearn: 0.3579378\ttotal: 46.8s\tremaining: 2m 8s\n",
      "500:\tlearn: 0.3482276\ttotal: 57.5s\tremaining: 1m 54s\n",
      "600:\tlearn: 0.3396237\ttotal: 1m 8s\tremaining: 1m 42s\n",
      "700:\tlearn: 0.3318851\ttotal: 1m 19s\tremaining: 1m 30s\n",
      "800:\tlearn: 0.3246693\ttotal: 1m 29s\tremaining: 1m 18s\n",
      "900:\tlearn: 0.3175379\ttotal: 1m 41s\tremaining: 1m 7s\n",
      "1000:\tlearn: 0.3112177\ttotal: 1m 52s\tremaining: 56.1s\n",
      "1100:\tlearn: 0.3042084\ttotal: 2m 5s\tremaining: 45.6s\n",
      "1200:\tlearn: 0.2985914\ttotal: 2m 16s\tremaining: 34s\n",
      "1300:\tlearn: 0.2931235\ttotal: 2m 27s\tremaining: 22.6s\n",
      "1400:\tlearn: 0.2878558\ttotal: 2m 40s\tremaining: 11.3s\n",
      "1499:\tlearn: 0.2834176\ttotal: 2m 52s\tremaining: 0us\n",
      "RMSE: 0.3985872166735667\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop(columns=[target_variable])\n",
    "y = train_data[target_variable]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# categorical_features = ['location']\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].fillna('Unknown')\n",
    "    X_test[col] = X_test[col].fillna('Unknown')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    text_features=['text'],\n",
    "    cat_features=categorical_features,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    target\n",
      "0   0  0.581030\n",
      "1   2  0.394270\n",
      "2   3  0.721698\n",
      "3   9  0.386842\n",
      "4  11  0.727788\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      3263 non-null   int64  \n",
      " 1   target  3263 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 51.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_features:\n",
    "    test_data[col] = test_data[col].fillna('Unknown')\n",
    "\n",
    "test_pred = model.predict(test_data)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'target': test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('NLPwDT_pred_catboost.csv', index=False)\n",
    "\n",
    "print(submission.head())\n",
    "print(submission.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

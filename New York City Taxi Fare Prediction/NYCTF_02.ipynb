{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = 'data/new-york-city-taxi-fare-prediction/train.csv'\n",
    "test_path = 'data/new-york-city-taxi-fare-prediction/test.csv'\n",
    "weather_path = 'data/New York 2013-01-01 to 2015-06-30.csv'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_path, nrows=100000)  # Ограничиваем размер выборки для скорости\n",
    "test_data = pd.read_csv(test_path)\n",
    "weather_data = pd.read_csv(weather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Самая ранняя дата: 2009-01-01 00:41:00+00:00\n",
      "Самая поздняя дата: 2015-06-30 22:54:07+00:00\n",
      "test\n",
      "Самая ранняя дата: 2009-01-01 11:04:24+00:00\n",
      "Самая поздняя дата: 2015-06-30 20:03:50+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>description</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>55.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01T07:20:12</td>\n",
       "      <td>2013-01-01T16:39:31</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>72505394728,KEWR,KLGA,72502014734,KNYC,7250301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>49.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-02T07:20:17</td>\n",
       "      <td>2013-01-02T16:40:22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>72505394728,KEWR,KLGA,72502014734,KNYC,7250301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-03T07:20:19</td>\n",
       "      <td>2013-01-03T16:41:16</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>72505394728,KEWR,KLGA,72502014734,KNYC,7250301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>53.8</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-04T07:20:20</td>\n",
       "      <td>2013-01-04T16:42:10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>72505394728,KEWR,KLGA,72502014734,KNYC,7250301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>48.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-05T07:20:18</td>\n",
       "      <td>2013-01-05T16:43:06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Clearing in the afternoon.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>72505394728,KEWR,KLGA,72502014734,KNYC,7250301...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  \\\n",
       "0  New York  2013-01-01      4.2     -2.5   2.7           0.9         -10.3   \n",
       "1  New York  2013-01-02      0.4     -5.2  -2.4          -4.3         -10.9   \n",
       "2  New York  2013-01-03      0.3     -3.8  -1.7          -1.9          -7.2   \n",
       "3  New York  2013-01-04      3.0     -0.6   1.3          -1.5          -4.8   \n",
       "4  New York  2013-01-05      6.0      0.2   2.7           4.3          -4.9   \n",
       "\n",
       "   feelslike   dew  humidity  ...  solarenergy  uvindex  severerisk  \\\n",
       "0       -1.3  -5.3      55.8  ...          2.2        1         NaN   \n",
       "1       -7.0 -11.6      49.6  ...          8.2        4         NaN   \n",
       "2       -5.5  -9.7      55.0  ...          7.4        3         NaN   \n",
       "3       -3.1  -7.1      53.8  ...          9.5        5         NaN   \n",
       "4       -0.5  -7.2      48.5  ...          9.8        5         NaN   \n",
       "\n",
       "               sunrise               sunset  moonphase        conditions  \\\n",
       "0  2013-01-01T07:20:12  2013-01-01T16:39:31       0.65  Partially cloudy   \n",
       "1  2013-01-02T07:20:17  2013-01-02T16:40:22       0.68  Partially cloudy   \n",
       "2  2013-01-03T07:20:19  2013-01-03T16:41:16       0.72  Partially cloudy   \n",
       "3  2013-01-04T07:20:20  2013-01-04T16:42:10       0.75  Partially cloudy   \n",
       "4  2013-01-05T07:20:18  2013-01-05T16:43:06       0.79  Partially cloudy   \n",
       "\n",
       "                         description               icon  \\\n",
       "0  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "1  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "2  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "3  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "4         Clearing in the afternoon.  partly-cloudy-day   \n",
       "\n",
       "                                            stations  \n",
       "0  72505394728,KEWR,KLGA,72502014734,KNYC,7250301...  \n",
       "1  72505394728,KEWR,KLGA,72502014734,KNYC,7250301...  \n",
       "2  72505394728,KEWR,KLGA,72502014734,KNYC,7250301...  \n",
       "3  72505394728,KEWR,KLGA,72502014734,KNYC,7250301...  \n",
       "4  72505394728,KEWR,KLGA,72502014734,KNYC,7250301...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем в datetime, если это еще не сделано\n",
    "train_data['pickup_datetime'] = pd.to_datetime(train_data['pickup_datetime'])\n",
    "test_data['pickup_datetime'] = pd.to_datetime(test_data['pickup_datetime'])\n",
    "\n",
    "# Находим минимальную и максимальную дату\n",
    "min_date = train_data['pickup_datetime'].min()\n",
    "max_date = train_data['pickup_datetime'].max()\n",
    "\n",
    "test_min_date = test_data['pickup_datetime'].min()\n",
    "test_max_date = test_data['pickup_datetime'].max()\n",
    "\n",
    "print(\"train\")\n",
    "print(f\"Самая ранняя дата: {min_date}\")\n",
    "print(f\"Самая поздняя дата: {max_date}\")\n",
    "print(\"test\")\n",
    "print(f\"Самая ранняя дата: {test_min_date}\")\n",
    "print(f\"Самая поздняя дата: {test_max_date}\")\n",
    "\n",
    "weather_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_585392/149752938.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_weather_data[col].fillna(df_weather_data[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_585392/149752938.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_weather_data[col].fillna(df_weather_data[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data_merge_weather(df):\n",
    "    # Преобразуем datetime в формат datetime\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    weather_data['datetime'] = pd.to_datetime(weather_data['datetime'])\n",
    "    \n",
    "    # Объединяем данные о поездках с данными о погоде по дате\n",
    "    df_weather_data = pd.merge(\n",
    "        df,\n",
    "        weather_data,\n",
    "        left_on=df['pickup_datetime'].dt.date,\n",
    "        right_on=weather_data['datetime'].dt.date,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Заполнение пропусков средними значениями\n",
    "    weather_columns = ['temp', 'humidity', 'precip', 'windspeed']\n",
    "    for col in weather_columns:\n",
    "        df_weather_data[col].fillna(df_weather_data[col].mean(), inplace=True)\n",
    "        \n",
    "    # Добавление бинарного признака наличия данных о погоде\n",
    "    df_weather_data['weather_data_available'] = df_weather_data['temp'].notna().astype(int)\n",
    "    \n",
    "    # Создание признаков времени суток и дня недели\n",
    "    df_weather_data['hour'] = df_weather_data['pickup_datetime'].dt.hour\n",
    "    df_weather_data['day_of_week'] = df_weather_data['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "    return df_weather_data\n",
    "\n",
    "\n",
    "train_data = preprocess_data_merge_weather(train_data)\n",
    "test_data = preprocess_data_merge_weather(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Удаляем некорректные координаты\n",
    "    df = df[\n",
    "        (df['pickup_latitude'].between(-90, 90)) & \n",
    "        (df['dropoff_latitude'].between(-90, 90)) & \n",
    "        (df['pickup_longitude'].between(-180, 180)) & \n",
    "        (df['dropoff_longitude'].between(-180, 180))\n",
    "    ].dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "\n",
    "    # Преобразуем координаты в float\n",
    "    df[['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']] = \\\n",
    "        df[['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']].astype(float)\n",
    "\n",
    "    # Функция Haversine distance\n",
    "    def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "        R = 6371\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "        return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    df['haversine_distance'] = haversine_distance(\n",
    "        df['pickup_latitude'], df['pickup_longitude'],\n",
    "        df['dropoff_latitude'], df['dropoff_longitude']\n",
    "    )\n",
    "\n",
    "    # Manhattan distance\n",
    "    df['manhattan_distance'] = (\n",
    "        abs(df['pickup_latitude'] - df['dropoff_latitude']) +\n",
    "        abs(df['pickup_longitude'] - df['dropoff_longitude'])\n",
    "    ) * 111\n",
    "\n",
    "    # Признак направления движения (bearing)\n",
    "    def bearing(lat1, lon1, lat2, lon2):\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlon = lon2 - lon1\n",
    "        x = np.sin(dlon) * np.cos(lat2)\n",
    "        y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
    "        return np.degrees(np.arctan2(x, y))\n",
    "\n",
    "    df['bearing'] = bearing(\n",
    "        df['pickup_latitude'], df['pickup_longitude'],\n",
    "        df['dropoff_latitude'], df['dropoff_longitude']\n",
    "    )\n",
    "\n",
    "    # Координаты аэропортов и центра города\n",
    "    JFK = (40.6413, -73.7781)\n",
    "    LGA = (40.7769, -73.8740)\n",
    "    EWR = (40.6895, -74.1745)\n",
    "    DOWNTOWN = (40.7580, -73.9855)\n",
    "\n",
    "    def is_near_location(lat, lon, location, threshold=1):\n",
    "        return int(geodesic((lat, lon), location).km < threshold)\n",
    "\n",
    "    df['pickup_near_airport'] = df.apply(\n",
    "        lambda row: is_near_location(row['pickup_latitude'], row['pickup_longitude'], JFK) or\n",
    "                    is_near_location(row['pickup_latitude'], row['pickup_longitude'], LGA) or\n",
    "                    is_near_location(row['pickup_latitude'], row['pickup_longitude'], EWR), axis=1\n",
    "    )\n",
    "\n",
    "    df['dropoff_near_airport'] = df.apply(\n",
    "        lambda row: is_near_location(row['dropoff_latitude'], row['dropoff_longitude'], JFK) or\n",
    "                    is_near_location(row['dropoff_latitude'], row['dropoff_longitude'], LGA) or\n",
    "                    is_near_location(row['dropoff_latitude'], row['dropoff_longitude'], EWR), axis=1\n",
    "    )\n",
    "\n",
    "    df['pickup_near_downtown'] = df.apply(\n",
    "        lambda row: is_near_location(row['pickup_latitude'], row['pickup_longitude'], DOWNTOWN), axis=1\n",
    "    )\n",
    "\n",
    "    df['dropoff_near_downtown'] = df.apply(\n",
    "        lambda row: is_near_location(row['dropoff_latitude'], row['dropoff_longitude'], DOWNTOWN), axis=1\n",
    "    )\n",
    "\n",
    "    # Извлекаем временные признаки (если есть столбец 'pickup_datetime')\n",
    "    if 'pickup_datetime' in df.columns:\n",
    "        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "        df['hour'] = df['pickup_datetime'].dt.hour\n",
    "        df['day_of_week'] = df['pickup_datetime'].dt.weekday\n",
    "        df['month'] = df['pickup_datetime'].dt.month\n",
    "        \n",
    "        df['minute'] = df['pickup_datetime'].dt.minute\n",
    "        df['day_of_month'] = df['pickup_datetime'].dt.day\n",
    "        df['year'] = df['pickup_datetime'].dt.year\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "        df['is_night_trip'] = ((df['hour'] >= 23) | (df['hour'] <= 5)).astype(int)\n",
    "        df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9)) | ((df['hour'] >= 16) & (df['hour'] <= 19))\n",
    "        df['season'] = df['month'] % 12 // 3 + 1\n",
    "        \n",
    "        holidays = USFederalHolidayCalendar().holidays(start='2009-01-01', end='2015-12-31')\n",
    "        df['is_holiday'] = df['pickup_datetime'].dt.date.isin(holidays).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = preprocess_data(train_data)\n",
    "test_data = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "categorical features in the model are set to ['preciptype', 'severerisk', 'pickup_near_airport', 'dropoff_near_airport', 'pickup_near_downtown', 'dropoff_near_downtown', 'is_weekend', 'is_night_trip', 'is_rush_hour', 'season']. categorical features passed to fit function are set to [11, 23, 29, 30, 31, 32, 39, 40, 41, 42]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m test_data[numeric_columns] \u001b[38;5;241m=\u001b[39m test_data[numeric_columns]\u001b[38;5;241m.\u001b[39mfillna(test_data[numeric_columns]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     70\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, cat_features\u001b[38;5;241m=\u001b[39mcategorical_features)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Оцениваем модель\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/catboost/core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/catboost/core.py:2395\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2395\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2405\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2406\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/catboost/core.py:2271\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, FeaturesData):\n\u001b[1;32m   2267\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeaturesData is deprecated for using in fit function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2268\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand soon will not be supported. If you want to use FeaturesData, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2269\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease pass it to Pool initialization and use Pool in fit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2271\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m \u001b[43m_process_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2273\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/catboost/core.py:2213\u001b[0m, in \u001b[0;36m_process_feature_indices\u001b[0;34m(feature_indices, pool, params, param_name)\u001b[0m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mset\u001b[39m(feature_indices) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mset\u001b[39m(params[param_name]):\n\u001b[0;32m-> 2213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(feature_type_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features in the model are set to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(params[param_name]) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   2214\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m feature_type_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features passed to fit function are set to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(feature_indices))\n\u001b[1;32m   2215\u001b[0m     feature_indices \u001b[38;5;241m=\u001b[39m params[param_name]\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m params[param_name]\n",
      "\u001b[0;31mCatBoostError\u001b[0m: categorical features in the model are set to ['preciptype', 'severerisk', 'pickup_near_airport', 'dropoff_near_airport', 'pickup_near_downtown', 'dropoff_near_downtown', 'is_weekend', 'is_night_trip', 'is_rush_hour', 'season']. categorical features passed to fit function are set to [11, 23, 29, 30, 31, 32, 39, 40, 41, 42]"
     ]
    }
   ],
   "source": [
    "# Преобразуем время в формат количества секунд с начала эпохи или как разницу между временем и базовой датой (например, 2000-01-01)\n",
    "train_data['sunrise'] = pd.to_datetime(train_data['sunrise'], errors='coerce')\n",
    "train_data['sunset'] = pd.to_datetime(train_data['sunset'], errors='coerce')\n",
    "\n",
    "test_data['sunrise'] = pd.to_datetime(test_data['sunrise'], errors='coerce')\n",
    "test_data['sunset'] = pd.to_datetime(test_data['sunset'], errors='coerce')\n",
    "\n",
    "# Преобразуем в количество секунд с начала эпохи или от базовой даты (например, 2000-01-01)\n",
    "train_data['sunrise_seconds'] = (train_data['sunrise'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "train_data['sunset_seconds'] = (train_data['sunset'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "\n",
    "test_data['sunrise_seconds'] = (test_data['sunrise'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "test_data['sunset_seconds'] = (test_data['sunset'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "\n",
    "# Убедимся, что у нас больше нет строковых значений в данных, где ожидаются числовые значения\n",
    "train_data = train_data.drop(columns=['sunrise', 'sunset'])\n",
    "test_data = test_data.drop(columns=['sunrise', 'sunset'])\n",
    "\n",
    "# Теперь в features должны быть указаны правильные столбцы\n",
    "features = [\n",
    "    # Погодные признаки\n",
    "    'tempmax', 'tempmin', 'temp', 'feelslikemax', 'feelslikemin', 'feelslike', \n",
    "    'dew', 'humidity', 'precip', 'precipprob', 'precipcover', 'preciptype', \n",
    "    'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', \n",
    "    'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', \n",
    "    'severerisk', 'sunrise_seconds', 'sunset_seconds',\n",
    "    \n",
    "    # Прочие признаки\n",
    "    'haversine_distance', 'manhattan_distance', 'bearing', 'pickup_near_airport', \n",
    "    'dropoff_near_airport', 'pickup_near_downtown', 'dropoff_near_downtown', \n",
    "    'hour', 'day_of_week', 'month', 'minute', 'day_of_month', 'year', \n",
    "    'is_weekend', 'is_night_trip', 'is_rush_hour', 'season'\n",
    "]\n",
    "\n",
    "# Подготовка данных для обучения\n",
    "X = train_data[features]\n",
    "y = train_data['fare_amount']\n",
    "\n",
    "# Разделяем данные на тренировочные и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучаем модель CatBoost, передавая индексы категориальных признаков\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "categorical_features = ['preciptype', 'severerisk', 'pickup_near_airport', 'dropoff_near_airport', 'pickup_near_downtown', 'dropoff_near_downtown', 'is_weekend', 'is_night_trip', 'is_rush_hour', 'season']\n",
    "\n",
    "# Заполняем пропущенные значения в категориальных признаках строкой \"unknown\"\n",
    "# for col in categorical_features:\n",
    "#     train_data[col] = train_data[col].fillna(\"unknown\")\n",
    "#     test_data[col] = test_data[col].fillna(\"unknown\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Заменяем NaN значениями в категориальных признаках на 'unknown'\n",
    "    train_data[col] = train_data[col].fillna(\"unknown\")\n",
    "    test_data[col] = test_data[col].fillna(\"unknown\")\n",
    "\n",
    "# Убедитесь, что категориальные признаки в данных имеют тип \"category\"\n",
    "for col in categorical_features:\n",
    "    train_data[col] = train_data[col].astype('category')\n",
    "    test_data[col] = test_data[col].astype('category')\n",
    "\n",
    "\n",
    "# Заполняем пропущенные значения в числовых признаках (например, на медиану или среднее)\n",
    "numeric_columns = train_data.select_dtypes(include=['float64', 'int64']).columns.drop('fare_amount')\n",
    "train_data[numeric_columns] = train_data[numeric_columns].fillna(train_data[numeric_columns].median())\n",
    "test_data[numeric_columns] = test_data[numeric_columns].fillna(test_data[numeric_columns].median())\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, depth=7, learning_rate=0.1, loss_function='RMSE', verbose=200, cat_features=categorical_features)\n",
    "model.fit(X_train, y_train, cat_features=[X.columns.get_loc(col) for col in categorical_features])\n",
    "\n",
    "# Оцениваем модель\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# Применяем модель к тестовым данным\n",
    "X_test = test_data[features]\n",
    "test_data['fare_amount'] = model.predict(X_test)\n",
    "\n",
    "# Сохраняем предсказания\n",
    "submission = test_data[['key', 'fare_amount']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Предсказания сохранены в submission.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['sunrise', 'sunset'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msunset_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Подготовка данных для обучения\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m y \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Разделяем данные на тренировочные и тестовые\u001b[39;00m\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/home/repos/jupiter/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['sunrise', 'sunset'] not in index\""
     ]
    }
   ],
   "source": [
    "features = [\n",
    "        # Погодные признаки\n",
    "    'tempmax',              # Максимальная температура\n",
    "    'tempmin',              # Минимальная температура\n",
    "    'temp',                 # Средняя температура\n",
    "    'feelslikemax',         # Максимальная температура по ощущениям\n",
    "    'feelslikemin',         # Минимальная температура по ощущениям\n",
    "    'feelslike',            # Средняя температура по ощущениям\n",
    "    'dew',                  # Точка росы\n",
    "    'humidity',             # Влажность воздуха\n",
    "    'precip',               # Количество осадков\n",
    "    'precipprob',           # Вероятность осадков\n",
    "    'precipcover',          # Покрытие осадками\n",
    "    'preciptype',           # Тип осадков (дождь, снег и т.д.)\n",
    "    'snow',                 # Количество снега\n",
    "    'snowdepth',            # Глубина снега\n",
    "    'windgust',             # Порывы ветра\n",
    "    'windspeed',            # Скорость ветра\n",
    "    'winddir',              # Направление ветра\n",
    "    'sealevelpressure',     # Атмосферное давление\n",
    "    'cloudcover',           # Покрытие облаками\n",
    "    'visibility',           # Видимость\n",
    "    'solarradiation',       # Солнечное излучение\n",
    "    'solarenergy',          # Солнечная энергия\n",
    "    'uvindex',              # Индекс ультрафиолетового излучения\n",
    "    'severerisk',           # Оценка риска катастроф\n",
    "    'sunrise',              # Время восхода солнца\n",
    "    'sunset',               # Время заката солнца\n",
    "    'moonphase',            # Фаза Луны\n",
    "\n",
    "    \n",
    "    'haversine_distance', 'manhattan_distance', 'bearing',\n",
    "    'pickup_near_airport', 'dropoff_near_airport',\n",
    "    'pickup_near_downtown', 'dropoff_near_downtown',\n",
    "    'hour', 'day_of_week', 'month', 'minute', 'day_of_month', \n",
    "    'year', 'is_weekend', 'is_night_trip', 'is_rush_hour', 'season'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Задаем категориальные признаки (например, 'preciptype')\n",
    "categorical_features = [\n",
    "    'preciptype',  # Тип осадков (дождь, снег и т.д.)\n",
    "    'season'       # Сезон (например, весна, лето, осень, зима)\n",
    "]\n",
    "\n",
    "for col in categorical_features:\n",
    "    train_data[col] = train_data[col].fillna('missing')\n",
    "    test_data[col] = test_data[col].fillna('missing')\n",
    "\n",
    "\n",
    "# Преобразуем время в формат количества секунд с начала эпохи или как разницу между временем и базовой датой\n",
    "train_data['sunrise'] = pd.to_datetime(train_data['sunrise'], errors='coerce')\n",
    "train_data['sunset'] = pd.to_datetime(train_data['sunset'], errors='coerce')\n",
    "\n",
    "test_data['sunrise'] = pd.to_datetime(test_data['sunrise'], errors='coerce')\n",
    "test_data['sunset'] = pd.to_datetime(test_data['sunset'], errors='coerce')\n",
    "\n",
    "# Преобразуем в количество секунд с начала эпохи или от базовой даты (например, 2000-01-01)\n",
    "train_data['sunrise_seconds'] = (train_data['sunrise'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "train_data['sunset_seconds'] = (train_data['sunset'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "\n",
    "test_data['sunrise_seconds'] = (test_data['sunrise'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "test_data['sunset_seconds'] = (test_data['sunset'] - pd.Timestamp(\"2000-01-01\")) // pd.Timedelta(seconds=1)\n",
    "\n",
    "# Убедимся, что у нас больше нет строковых значений в данных, где ожидаются числовые значения\n",
    "train_data = train_data.drop(columns=['sunrise', 'sunset'])\n",
    "test_data = test_data.drop(columns=['sunrise', 'sunset'])\n",
    "\n",
    "# Добавляем эти новые признаки в список признаков\n",
    "features.append('sunrise_seconds')\n",
    "features.append('sunset_seconds')\n",
    "\n",
    "# Подготовка данных для обучения\n",
    "X = train_data[features]\n",
    "y = train_data['fare_amount']\n",
    "\n",
    "# Разделяем данные на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучаем модель CatBoost, передавая индексы категориальных признаков\n",
    "model = CatBoostRegressor(iterations=1000, depth=7, learning_rate=0.1, loss_function='RMSE', verbose=200)\n",
    "model.fit(X_train, y_train, cat_features=[X.columns.get_loc(col) for col in categorical_features])\n",
    "\n",
    "# Оцениваем модель\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# Применяем модель к тестовым данным\n",
    "X_test = test_data[features]\n",
    "test_data['fare_amount'] = model.predict(X_test)\n",
    "\n",
    "# Сохраняем предсказания\n",
    "submission = test_data[['key', 'fare_amount']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Предсказания сохранены в submission.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 9.0954648\ttotal: 21.5ms\tremaining: 21.4s\n",
      "200:\tlearn: 4.2027676\ttotal: 1.39s\tremaining: 5.54s\n",
      "400:\tlearn: 3.8952039\ttotal: 2.64s\tremaining: 3.94s\n",
      "600:\tlearn: 3.6390415\ttotal: 3.79s\tremaining: 2.52s\n",
      "800:\tlearn: 3.4620147\ttotal: 4.99s\tremaining: 1.24s\n",
      "999:\tlearn: 3.3245413\ttotal: 6.15s\tremaining: 0us\n",
      "RMSE: 4.526683273634654\n",
      "Предсказания сохранены в submission.csv!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/repos/jupiter/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'haversine_distance', 'manhattan_distance', 'bearing',\n",
    "    'pickup_near_airport', 'dropoff_near_airport',\n",
    "    'pickup_near_downtown', 'dropoff_near_downtown',\n",
    "    'hour', 'day_of_week', 'month', 'minute', 'day_of_month', \n",
    "    'year', 'is_weekend', 'is_night_trip', 'is_rush_hour', 'season'\n",
    "]\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data['fare_amount']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучаем модель CatBoost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, depth=7, learning_rate=0.1, loss_function='RMSE', verbose=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Оцениваем модель\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "X_test = test_data[features]\n",
    "\n",
    "# Делаем предсказание\n",
    "test_data['fare_amount'] = model.predict(X_test)\n",
    "\n",
    "# Сохраняем результат\n",
    "submission = test_data[['key', 'fare_amount']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Предсказания сохранены в submission.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'trip_duration' in train_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
